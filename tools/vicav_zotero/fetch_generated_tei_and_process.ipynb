{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script to automate the export and manipulation of the VICAV-library\n",
    "\n",
    "## Import Package eTree to parse XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import asyncio\n",
    "import aiohttp\n",
    "# this module is needed to make asyncio.run work inside the notebook as well as in the generated python script\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define name-space for xml-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmlns = {\"tei\": \"http://www.tei-c.org/ns/1.0\", \"xml\":\"http://www.w3.org/XML/1998/namespace\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access to the VICAV Zotero library\n",
    "\n",
    "* Use API_TOKEN from environment to access Zotero\n",
    "* Set the Zotero group id for VICAV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_headers = {'Authorization': 'Bearer ' + os.environ['API_TOKEN']}\n",
    "group_id = \"2165756\"\n",
    "limit_downloads_to = None\n",
    "conn_limit=16\n",
    "total_timeout=600 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all items in the library\n",
    "\n",
    "Load items from Zotero group library\n",
    "\n",
    "    Args: \n",
    "        group_id (str): ID of a Zotero group\n",
    "        limit (int): number of items to retrieve from library, maximum is 100.\n",
    "        start (int): item number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_items(session, group_id:str,limit:int,start:int,itemType = None):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + \"?limit=\" + str(limit) + \"&start=\" + str(start) + (\"&itemType=\"+itemType if itemType is not None else \"\")\n",
    "    async with session.get(url=request_url, headers=request_headers) as response:\n",
    "        if response.status == 200:\n",
    "            parsed = json.loads(await response.text())\n",
    "            response_headers = response.headers\n",
    "        \n",
    "    return parsed, response_headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test1():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout) # 10 min\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test1, test_reponse_headers = await get_items(session, group_id,10,1000)\n",
    "        test1a, test_reponse_headersa = await get_items(session, group_id,10,300,\"note\")\n",
    "        print(test_reponse_headers, '\\n', test_reponse_headersa, '\\n', len(test1), ' ', len(test1a), '\\n', test1)\n",
    "asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get total number of items in group library\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group\n",
    "    \n",
    "    Returns:\n",
    "        int: number of items in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_number_items(group_id) -> int:\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return int(response.headers[\"Total-Results\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test2 = total_number_items(group_id)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get headers of Zotero-Api-Calls\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_headers(group_id):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return response.headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test3 = get_headers(group_id)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from headers\n",
    "\n",
    "    Args:\n",
    "        headers: http-headers of a response\n",
    "\n",
    "    Returns:\n",
    "        dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_from_headers(headers) -> dict:\n",
    "    link_list = headers[\"Link\"].split(\",\")\n",
    "    links = {}\n",
    "    for link_item in link_list:\n",
    "        #print(link_item)\n",
    "        link_type = link_item.split('; rel=\"')[1].replace('\"','').strip()\n",
    "        link_value = link_item.split('; rel=\"')[0].replace(\"<\",\"\").replace(\">\",\"\").strip()\n",
    "        links[link_type] = link_value\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test_headers = get_headers(group_id)\n",
    "test4 = get_links_from_headers(test_headers)\n",
    "print(test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all items of a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_all_items(session, group_id, itemType = None):\n",
    "    logging.info(\"Getting all items\" + ((\" of type \" + itemType) if itemType is not None else \"\") + \" now.\")\n",
    "    # empty list that will hold all items of the library\n",
    "    allitems=[]\n",
    "    \n",
    "    # settings to be used in the function to get the items (limit is max 100)\n",
    "    limit=100\n",
    "    start=0\n",
    "    \n",
    "    # get the first 200 items to start with\n",
    "    first_round=await get_items(session, group_id,limit,start,itemType)\n",
    "    allitems=allitems+first_round[0]\n",
    "    \n",
    "    # get the next link from the headers\n",
    "    next_url = get_links_from_headers(first_round[1])[\"next\"]\n",
    "    last_url = get_links_from_headers(first_round[1])[\"last\"]\n",
    "    # get items until next url is last url, then all items are fetched\n",
    "    while next_url != last_url:\n",
    "        logging.info(\"Getting items from \" + next_url)\n",
    "        async with session.get(url=next_url, headers=request_headers) as response:\n",
    "            if response.status == 200:\n",
    "                parsed = json.loads(await response.text())\n",
    "                response_headers = response.headers\n",
    "\n",
    "                allitems=allitems + parsed\n",
    "                urls = get_links_from_headers(response_headers)\n",
    "                if \"next\" in urls:\n",
    "                    next_url = urls[\"next\"]\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # get the last items of the group\n",
    "    response = requests.get(last_url)\n",
    "    if response.status_code == 200:\n",
    "        parsed = json.loads(response.text)\n",
    "        allitems=allitems + parsed\n",
    "    \n",
    "    return allitems"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test5():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test5 = await get_all_items(session, group_id)\n",
    "        print(test5)\n",
    "asyncio.run(test5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all items of a group library in a json file\n",
    "\n",
    "    Args:\n",
    "        group_id (str): ID of a Zotero group\n",
    "        filename (str): name of the export file including file-extension\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_all_items_to_file(group_id,filename) ->bool: \n",
    "    allitems = get_all_items(group_id)\n",
    "    with open(filename,\"w\") as f:\n",
    "        json.dump(allitems, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#export_all_items_to_file(group_id,\"export_grouplib.json\")\n",
    "with open(\"export_grouplib.json\",\"w\") as f:\n",
    "    json.dump(test5, f)\n",
    "all_items = test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store export in a file and get all item ids\n",
    "\n",
    "The export contains also the note items. These are child items of some other item in this export. They have a parent reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 10:20:11,225 - Grouplib export json already exists. Delete to fetch again (time consuming).\n",
      "2023-02-24 10:20:12,500 - Exported json.\n"
     ]
    }
   ],
   "source": [
    "json_file = \"export_grouplib.json\"\n",
    "item_ids = []\n",
    "note_ids = []\n",
    "async def get_generic_items(session):\n",
    "    if os.path.isfile(json_file):\n",
    "        logging.info(\"Grouplib export json already exists. Delete to fetch again (time consuming).\")\n",
    "        with open(json_file, 'r') as f:\n",
    "            all_items = json.load(f)    \n",
    "    else:\n",
    "        all_items = await get_all_items(session, group_id)\n",
    "    return all_items\n",
    "\n",
    "async def get_export_json():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_generic_items(session)\n",
    "    # all_items = test5\n",
    "    with open(json_file,\"w\") as f:\n",
    "        json.dump(all_items, f)\n",
    "        logging.info(\"Exported json.\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_id = item[\"key\"]\n",
    "        item_type = item[\"data\"][\"itemType\"]\n",
    "        if item_type == 'note':\n",
    "            note_ids.append(item_id)\n",
    "        else:\n",
    "            item_ids.append(item_id)\n",
    "    return all_items\n",
    "all_items = asyncio.run(get_export_json())\n",
    "all_items_map = {data[\"key\"]:data for data in all_items}\n",
    "all_notes_map = {data[\"data\"][\"parentItem\"]:data for data in [all_items_map[id] for id in note_ids]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(len(all_items), ' ', len(note_ids), ' ', len(item_ids), '\\n', item_ids[:10],\n",
    "      '\\nBibl items:\\n', dict(list(all_items_map.items())[:10]),\n",
    "      '\\nNote items:\\n', dict(list(all_notes_map.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the geo data and replace tags with geo refs\n",
    "\n",
    "geo data is in `../../vicav_biblio/vicav_geodata.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_data = ET.parse(\"../../vicav_biblio/vicav_geodata.xml\")\n",
    "place_by_name = {}\n",
    "p=1\n",
    "for place in geo_data.findall(\".//tei:listPlace/tei:place\", xmlns):\n",
    "    p=p+1\n",
    "    try:\n",
    "        place_by_name = {**place_by_name, **{place.find(\"./tei:placeName\",xmlns).text: {\"geo\": place.find(\".//tei:geo[@decls='#dd']\",xmlns).text, \"el\": place}}}\n",
    "    except AttributeError:\n",
    "        logging.info(\"Pos \"+str(p)+\" :\"+ET.tostring(place))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(geo_data.find(\".//tei:listPlace\", xmlns)[1].attrib[\"{http://www.w3.org/XML/1998/namespace}id\"], '\\n',\n",
    "    dict(list(place_by_name.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all TEIs from Zotero\n",
    "\n",
    "man nimmt die Liste mit den IDs der entries, baut für jeden entry die URL nach dem Muster  \n",
    "https://api.zotero.org/groups/2165756/items/944KQVKQ?format=tei  \n",
    "man lädt das mit GET requesst  \n",
    "dann aus dem response den body und parsed das mit ET from string, nimmt daraus das  \n",
    "`<biblStruct>` Element;  \n",
    "baut eine gemeinsame `<listBibl>` und fügt das geparste Element ein,  \n",
    "dann dumpt man den ganzen Element-Tree\n",
    "\n",
    "### Retrieves TEI of an item generated by Zotero\n",
    "\n",
    "Resolves place names to geo coordinates using the place by name dict created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "tag_parser = re.compile(r'(?P<geo_type>[^:]+):(?P<geo_name>[^[]+)(\\[(?P<long>[\\d.,]+) +(?P<lat>[\\d.,]+)])?')\n",
    "\n",
    "def create_geo_tag(tags_el, tag):\n",
    "    #starts with reg: geo: diaGroup: -> lookup, get geo location and create elemnt\n",
    "    # uses PEP 634, requires python 3.10+\n",
    "    m = tag_parser.match(tag)\n",
    "    match m.groupdict():\n",
    "        case {\"geo_type\": \"reg\" | \"geo\" | \"diaGroup\", \"geo_name\": geo_name, \"long\": long, \"lat\": lat}:\n",
    "            tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\")#, subtype=m.groupdict()[\"geo_type\"])\n",
    "            geo_name = geo_name.rstrip()\n",
    "            ET.SubElement(tag_note_el, \"name\", type=\"geo\").text = geo_name\n",
    "            if geo_name in place_by_name:\n",
    "                ET.SubElement(tag_note_el, \"geo\").text = place_by_name[geo_name][\"geo\"]\n",
    "            else:\n",
    "                ET.SubElement(tag_note_el, \"note\", type=\"missing_geo_data\")\n",
    "            return tag_note_el\n",
    "    if tag in place_by_name:\n",
    "        tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\", subtype=\"unmarked_geo\")\n",
    "        ET.SubElement(tag_note_el, \"name\", type=\"geo\").text = tag\n",
    "        ET.SubElement(tag_note_el, \"geo\").text = place_by_name[tag][\"geo\"]\n",
    "        return tag_note_el\n",
    "    ret = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "    ret.text = tag\n",
    "    return ret\n",
    "\n",
    "async def get_item_tei(group_id,item_id,session):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + item_id + \"?format=tei\"\n",
    "    bibl = None\n",
    "    note_for_item_id = \"\"\n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        async with session.get(url=request_url, headers=request_headers) as response:\n",
    "            response_text = await response.text()\n",
    "        list_bibl = ET.fromstring(response_text)\n",
    "        bibl = list_bibl.find(\"tei:biblStruct\",xmlns)\n",
    "        if bibl is None:\n",
    "            logging.info(\"There is no biblStruct in the response:\\n\"+response_text)\n",
    "            return bibl\n",
    "        if item_id in all_notes_map:\n",
    "            note_for_item_id = all_notes_map[item_id][\"data\"][\"note\"].replace(\"&\", \"&amp;\")\n",
    "            parsed_note = ET.fromstring(\"<note>\"+note_for_item_id+\"</note>\")\n",
    "            bibl.append(parsed_note)\n",
    "        tags_el = ET.SubElement(bibl, \"note\", type=\"tags\")\n",
    "        for o in all_items_map[item_id][\"data\"][\"tags\"]:\n",
    "            create_geo_tag(tags_el, o[\"tag\"])\n",
    "                \n",
    "    except asyncio.TimeoutError:\n",
    "        logging.info(\"Timeout fetching \" + item_id)\n",
    "    except xml.etree.ElementTree.ParseError:\n",
    "        logging.info(\"XML parser error in notes for item id \"+item_id+\"\\n\"+note_for_item_id)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + item_id)\n",
    "    logging.info(\"Fetched TEI for \" + item_id)\n",
    "    return bibl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 11:43:36,141 - Fetched TEI for DXNCFAMR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<biblStruct xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"journalArticle\" xml:id=\"Guidotti2019\" corresp=\"http://zotero.org/groups/2165756/items/DXNCFAMR\">\n",
      "  <analytic>\n",
      "    <title level=\"a\">On the possibility of applying the research methods of lexical availability studiesto Middle Arabic and dialectal Arabic texts</title>\n",
      "    <idno type=\"DOI\">10.24425/FOR.2019.130709</idno>\n",
      "    <author>\n",
      "      <forename>Giulia</forename>\n",
      "      <surname>Guidotti</surname>\n",
      "    </author>\n",
      "  </analytic>\n",
      "  <monogr>\n",
      "    <imprint>\n",
      "      <date>2019</date>\n",
      "      <note type=\"accessed\">2021-01-04T13:11:19Z</note>\n",
      "      <note type=\"url\">http://journals.pan.pl/dlibra/publication/130709</note>\n",
      "    </imprint>\n",
      "  </monogr>\n",
      "  <note>\n",
      "    <h2>Other</h2>\n",
      "    <i>Folia Orientalia</i> wydawane są od 1959 roku przez Komisję Orientalistyczną Oddziału PAN w Krakowie. <i>Folia Orientalia</i> są rocznikiem o zasięgu światowym, reprezentującym szeroko pojęte humanistyczne studia orientalistyczne, obejmujące arabistykę, iranistykę, turkologię, afrykanistykę, indologię, zwłaszcza tematykę językoznawczą (głównie językoznawstwo porównawcze afroazjatyckie), literaturoznawczą, historyczną, archeologiczną, kulturoznawczą, religioznawczą oraz związaną z historią sztuki, głównie z terenów Bliskiego, Środkowego i Dalekiego Wschodu oraz Afryki. <i>Folia Orientalia</i> publikują wyłącznie artykuły naukowe oraz recenzje prac naukowych. Języki publikacji: angielski (podstawowy), francuski, niemiecki, hiszpański, rosyjski, włoski (okazjonalnie także arabski, turecki). Jest to jedyne orientalistyczne czasopismo w Polsce o tak szerokim zasięgu światowym, jeśli chodzi zarówno skład Komitetu Doradczego, jak i recenzentów, a zwłaszcza autorów, często najwybitniejszych specjalistów reprezentujących największe i najważniejsze ośrodki studiów orientalistycznych ze wszystkich kontynentów.</note>\n",
      "  <note type=\"tags\">\n",
      "    <note type=\"tag\">\n",
      "      <name type=\"geo\">Maghreb</name>\n",
      "      <geo>27.750000 9.300000</geo>\n",
      "    </note>\n",
      "    <note type=\"tag\">\n",
      "      <name type=\"geo\">Morocco</name>\n",
      "      <geo>32.000000 -6.000000</geo>\n",
      "    </note>\n",
      "    <note type=\"tag\">vt:diachronic perspective</note>\n",
      "    <note type=\"tag\">vt:historical dialectology</note>\n",
      "    <note type=\"tag\">vt:lexicon</note>\n",
      "  </note>\n",
      "</biblStruct>\n"
     ]
    }
   ],
   "source": [
    "async def get_item_tei_test():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        test = await get_item_tei(group_id,\"DXNCFAMR\",session)\n",
    "        #test = await get_item_tei(group_id,\"6QNLQCG9\",session)\n",
    "    ET.indent(test)\n",
    "    ET.dump(test)\n",
    "asyncio.run(get_item_tei_test())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(\"Notes:\\n\", all_notes_map[\"944KQVKQ\"][\"data\"][\"note\"], \"\\nTags:\\n\", all_items_map[\"944KQVKQ\"][\"data\"][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ET.parse(\"listbibl_template.xml\")\n",
    "list_bibl = template.find(\"tei:text/tei:body/tei:listBibl\",xmlns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load template containing a listBibl-element that will be filled with the retrieved biblStruct elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "ET.dump(list_bibl)\n",
    "list_bibl.append(test)\n",
    "ET.dump(list_bibl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the TEI\n",
    "\n",
    "* For each item-id get the TEI and append it to list-bibl\n",
    "* Save the resulting XML\n",
    "* Save errors for further inspection\n",
    "\n",
    "We need to consider https://www.zotero.org/support/dev/web_api/v3/basics#rate_limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 11:43:52,974 - Fetching at most 100 TEI/XML.\n",
      "2023-02-24 11:43:53,859 - Fetched TEI for N2NCTC8C\n",
      "2023-02-24 11:43:53,877 - Fetched TEI for B6L9AIMZ\n",
      "2023-02-24 11:43:53,889 - Fetched TEI for JYWMA77R\n",
      "2023-02-24 11:43:53,890 - Fetched TEI for EYRYK2V5\n",
      "2023-02-24 11:43:53,901 - Fetched TEI for NPJ679RJ\n",
      "2023-02-24 11:43:53,902 - Fetched TEI for QUCSQL79\n",
      "2023-02-24 11:43:53,907 - Fetched TEI for ZPP5LFIZ\n",
      "2023-02-24 11:43:53,916 - Fetched TEI for 6KWTRZHW\n",
      "2023-02-24 11:43:53,920 - Fetched TEI for BBB3B6VY\n",
      "2023-02-24 11:43:53,927 - Fetched TEI for RCI9I9AM\n",
      "2023-02-24 11:43:53,929 - Fetched TEI for E9GJGZZ7\n",
      "2023-02-24 11:43:53,935 - Fetched TEI for RUFEDDWU\n",
      "2023-02-24 11:43:53,936 - Fetched TEI for NIGWMNVB\n",
      "2023-02-24 11:43:53,938 - Fetched TEI for 6EPNLRXU\n",
      "2023-02-24 11:43:53,942 - Fetched TEI for 4RQ672D6\n",
      "2023-02-24 11:43:53,962 - Fetched TEI for 5AGSDUQK\n",
      "2023-02-24 11:43:54,222 - Fetched TEI for 94YGTTUX\n",
      "2023-02-24 11:43:54,308 - Fetched TEI for RNJVZ5ZY\n",
      "2023-02-24 11:43:54,344 - Fetched TEI for LXDBHINC\n",
      "2023-02-24 11:43:54,351 - Fetched TEI for PYD8MYVU\n",
      "2023-02-24 11:43:54,366 - Fetched TEI for RLWHIEMA\n",
      "2023-02-24 11:43:54,368 - Fetched TEI for GLZJDZJ8\n",
      "2023-02-24 11:43:54,371 - Fetched TEI for VFRAUIVS\n",
      "2023-02-24 11:43:54,378 - Fetched TEI for CUBE7ZWN\n",
      "2023-02-24 11:43:54,385 - Fetched TEI for M7UJPP23\n",
      "2023-02-24 11:43:54,386 - Fetched TEI for FHR8ZFB4\n",
      "2023-02-24 11:43:54,398 - Fetched TEI for L68WMCM6\n",
      "2023-02-24 11:43:54,409 - Fetched TEI for 7Z7K7GT5\n",
      "2023-02-24 11:43:54,414 - Fetched TEI for VHZ3ZJFP\n",
      "2023-02-24 11:43:54,420 - Fetched TEI for 8PDALG3N\n",
      "2023-02-24 11:43:54,422 - Fetched TEI for YHWQXEEK\n",
      "2023-02-24 11:43:54,423 - Fetched TEI for JQAHK9JL\n",
      "2023-02-24 11:43:54,706 - Fetched TEI for JZDS8J9B\n",
      "2023-02-24 11:43:54,760 - Fetched TEI for Q4YVVGBF\n",
      "2023-02-24 11:43:54,794 - Fetched TEI for H7UD2GEC\n",
      "2023-02-24 11:43:54,812 - Fetched TEI for QQMMM54Z\n",
      "2023-02-24 11:43:54,818 - Fetched TEI for RI9A62MM\n",
      "2023-02-24 11:43:54,823 - Fetched TEI for M6QDWLJX\n",
      "2023-02-24 11:43:54,825 - Fetched TEI for LZZRXQFX\n",
      "2023-02-24 11:43:54,827 - Fetched TEI for ET9E3AMT\n",
      "2023-02-24 11:43:54,837 - Fetched TEI for 4TEFG4GR\n",
      "2023-02-24 11:43:54,845 - Fetched TEI for 4U4PXA2U\n",
      "2023-02-24 11:43:54,864 - Fetched TEI for ELCV47RV\n",
      "2023-02-24 11:43:54,869 - Fetched TEI for SV9Z4D6Y\n",
      "2023-02-24 11:43:54,875 - Fetched TEI for 6E9C9WVK\n",
      "2023-02-24 11:43:54,876 - Fetched TEI for UGX6U9FI\n",
      "2023-02-24 11:43:54,880 - Fetched TEI for CNWWGLDV\n",
      "2023-02-24 11:43:54,882 - Fetched TEI for 3E63NIP8\n",
      "2023-02-24 11:43:55,153 - Fetched TEI for 3UPQD47X\n",
      "2023-02-24 11:43:55,166 - Fetched TEI for H6SUTQTH\n",
      "2023-02-24 11:43:55,280 - Fetched TEI for Y6SXHEX3\n",
      "2023-02-24 11:43:55,283 - Fetched TEI for FERNHSEK\n",
      "2023-02-24 11:43:55,287 - Fetched TEI for Y4D4EC7N\n",
      "2023-02-24 11:43:55,317 - Fetched TEI for W6ZY4Q9I\n",
      "2023-02-24 11:43:55,318 - Fetched TEI for AIGGEYJV\n",
      "2023-02-24 11:43:55,340 - Fetched TEI for 7BU9GRUD\n",
      "2023-02-24 11:43:55,356 - Fetched TEI for RTU42GAI\n",
      "2023-02-24 11:43:55,369 - Fetched TEI for 7U2D3ZZ5\n",
      "2023-02-24 11:43:55,373 - Fetched TEI for ASDW7JWZ\n",
      "2023-02-24 11:43:55,378 - Fetched TEI for 9KV8ZDXM\n",
      "2023-02-24 11:43:55,381 - Fetched TEI for AXH49C7Z\n",
      "2023-02-24 11:43:55,387 - Fetched TEI for TSVAJM63\n",
      "2023-02-24 11:43:55,389 - Fetched TEI for 5XQZBKWH\n",
      "2023-02-24 11:43:55,403 - Fetched TEI for 2ZCSZC6S\n",
      "2023-02-24 11:43:55,552 - Fetched TEI for JLH7WA7R\n",
      "2023-02-24 11:43:55,630 - Fetched TEI for ZZ7XM6L9\n",
      "2023-02-24 11:43:55,636 - Fetched TEI for 8DRBCP9U\n",
      "2023-02-24 11:43:55,665 - Fetched TEI for MXTB9WP8\n",
      "2023-02-24 11:43:55,738 - Fetched TEI for JR9RHV84\n",
      "2023-02-24 11:43:55,744 - Fetched TEI for VK3JI83R\n",
      "2023-02-24 11:43:55,769 - Fetched TEI for YHRMX2NB\n",
      "2023-02-24 11:43:55,774 - Fetched TEI for DPCK3SDE\n",
      "2023-02-24 11:43:55,793 - Fetched TEI for IX72ZLLZ\n",
      "2023-02-24 11:43:55,828 - Fetched TEI for F9J8RRIZ\n",
      "2023-02-24 11:43:55,829 - Fetched TEI for GJJ58FYI\n",
      "2023-02-24 11:43:55,838 - Fetched TEI for C27CE3UF\n",
      "2023-02-24 11:43:55,863 - Fetched TEI for PYDUUBGV\n",
      "2023-02-24 11:43:55,869 - Fetched TEI for 8Q9L9VE2\n",
      "2023-02-24 11:43:55,870 - Fetched TEI for 32FWAUB3\n",
      "2023-02-24 11:43:55,888 - Fetched TEI for IM6ZLUC3\n",
      "2023-02-24 11:43:55,994 - Fetched TEI for FXQSYEGH\n",
      "2023-02-24 11:43:56,099 - Fetched TEI for 243IXMTW\n",
      "2023-02-24 11:43:56,105 - Fetched TEI for I43HG54C\n",
      "2023-02-24 11:43:56,108 - Fetched TEI for ZNAJMUVP\n",
      "2023-02-24 11:43:56,118 - Fetched TEI for ZXDFZEVB\n",
      "2023-02-24 11:43:56,184 - Fetched TEI for VXHLTBE4\n",
      "2023-02-24 11:43:56,194 - Fetched TEI for 5L4GDW5I\n",
      "2023-02-24 11:43:56,199 - Fetched TEI for Z3HC36HT\n",
      "2023-02-24 11:43:56,234 - Fetched TEI for TVS8DCG7\n",
      "2023-02-24 11:43:56,279 - Fetched TEI for SEVFED87\n",
      "2023-02-24 11:43:56,289 - Fetched TEI for SHBSB66C\n",
      "2023-02-24 11:43:56,295 - Fetched TEI for IEMU68SH\n",
      "2023-02-24 11:43:56,347 - Fetched TEI for DB5KVYZ8\n",
      "2023-02-24 11:43:56,354 - Fetched TEI for N8LWJJUV\n",
      "2023-02-24 11:43:56,370 - Fetched TEI for RW7V776H\n",
      "2023-02-24 11:43:56,387 - Fetched TEI for 7AXF84RI\n",
      "2023-02-24 11:43:56,459 - Fetched TEI for K9BDS9HU\n",
      "2023-02-24 11:43:56,561 - Fetched TEI for XIZCMCH3\n",
      "2023-02-24 11:43:56,575 - Fetched TEI for 2YNKCJG6\n",
      "2023-02-24 11:43:56,576 - Fetched TEI for 7GRY9DGF\n",
      "2023-02-24 11:43:56,585 - TEI export done.\n",
      "2023-02-24 11:43:56,586 - Exported errors.json.\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "max_fetch = limit_downloads_to if limit_downloads_to is not None else len(item_ids)\n",
    "logging.info(\"Fetching at most \" + str(max_fetch) + \" TEI/XML.\")\n",
    "async def get_item_tei_from_group(item_id, session):\n",
    "    bibl_struct = await get_item_tei(group_id, item_id, session)\n",
    "    if bibl_struct:\n",
    "        list_bibl.append(bibl_struct)\n",
    "    else:\n",
    "        logging.debug(\"Can not append \" + item_id)\n",
    "        errors.append(item_id)\n",
    "\n",
    "async def async_download():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        await asyncio.gather(*[get_item_tei_from_group(item_id, session) for item_id in item_ids[:max_fetch]])\n",
    "\n",
    "asyncio.run(async_download())\n",
    "\n",
    "with open('TEI_export.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8')\n",
    "    logging.info(\"TEI export done.\")\n",
    "\n",
    "# Export IDs of items with errors\n",
    "with open(\"errors.json\",\"w\") as f:\n",
    "    json.dump(errors, f)\n",
    "    logging.info(\"Exported errors.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
