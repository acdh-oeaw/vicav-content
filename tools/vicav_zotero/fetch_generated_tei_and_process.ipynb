{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script to automate the export and manipulation of the VICAV-library\n",
    "\n",
    "## Import Package eTree to parse XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import asyncio\n",
    "import aiohttp\n",
    "# this module is needed to make asyncio.run work inside the notebook as well as in the generated python script\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define name-space for xml-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmlns = {\"tei\": \"http://www.tei-c.org/ns/1.0\", \"xml\":\"http://www.w3.org/XML/1998/namespace\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access to the VICAV Zotero library\n",
    "\n",
    "* Use API_TOKEN from environment to access Zotero\n",
    "* Set the Zotero group id for VICAV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_headers = {'Authorization': 'Bearer ' + os.environ['API_TOKEN']}\n",
    "group_id = \"2165756\"\n",
    "limit_downloads_to = None\n",
    "conn_limit=16\n",
    "total_timeout=600 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all items in the library\n",
    "\n",
    "Load items from Zotero group library\n",
    "\n",
    "    Args: \n",
    "        group_id (str): ID of a Zotero group\n",
    "        limit (int): number of items to retrieve from library, maximum is 100.\n",
    "        start (int): item number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_items(session, group_id:str,limit:int,start:int,itemType = None):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + \"?limit=\" + str(limit) + \"&start=\" + str(start) + (\"&itemType=\"+itemType if itemType is not None else \"\")\n",
    "    async with session.get(url=request_url, headers=request_headers) as response:\n",
    "        if response.status == 200:\n",
    "            parsed = json.loads(await response.text())\n",
    "            response_headers = response.headers\n",
    "        \n",
    "    return parsed, response_headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test1():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout) # 10 min\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test1, test_reponse_headers = await get_items(session, group_id,10,1000)\n",
    "        test1a, test_reponse_headersa = await get_items(session, group_id,10,300,\"note\")\n",
    "        print(test_reponse_headers, '\\n', test_reponse_headersa, '\\n', len(test1), ' ', len(test1a), '\\n', test1)\n",
    "asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get total number of items in group library\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group\n",
    "    \n",
    "    Returns:\n",
    "        int: number of items in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_number_items(group_id) -> int:\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return int(response.headers[\"Total-Results\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test2 = total_number_items(group_id)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get headers of Zotero-Api-Calls\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_headers(group_id):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return response.headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test3 = get_headers(group_id)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from headers\n",
    "\n",
    "    Args:\n",
    "        headers: http-headers of a response\n",
    "\n",
    "    Returns:\n",
    "        dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_from_headers(headers) -> dict:\n",
    "    link_list = headers[\"Link\"].split(\",\")\n",
    "    links = {}\n",
    "    for link_item in link_list:\n",
    "        #print(link_item)\n",
    "        link_type = link_item.split('; rel=\"')[1].replace('\"','').strip()\n",
    "        link_value = link_item.split('; rel=\"')[0].replace(\"<\",\"\").replace(\">\",\"\").strip()\n",
    "        links[link_type] = link_value\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test_headers = get_headers(group_id)\n",
    "test4 = get_links_from_headers(test_headers)\n",
    "print(test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all items of a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_all_items(session, group_id, itemType = None):\n",
    "    logging.info(\"Getting all items\" + ((\" of type \" + itemType) if itemType is not None else \"\") + \" now.\")\n",
    "    # empty list that will hold all items of the library\n",
    "    allitems=[]\n",
    "    \n",
    "    # settings to be used in the function to get the items (limit is max 100)\n",
    "    limit=100\n",
    "    start=0\n",
    "    \n",
    "    # get the first 200 items to start with\n",
    "    first_round=await get_items(session, group_id,limit,start,itemType)\n",
    "    allitems=allitems+first_round[0]\n",
    "    \n",
    "    # get the next link from the headers\n",
    "    next_url = get_links_from_headers(first_round[1])[\"next\"]\n",
    "    last_url = get_links_from_headers(first_round[1])[\"last\"]\n",
    "    # get items until next url is last url, then all items are fetched\n",
    "    while next_url != last_url:\n",
    "        logging.info(\"Getting items from \" + next_url)\n",
    "        async with session.get(url=next_url, headers=request_headers) as response:\n",
    "            if response.status == 200:\n",
    "                parsed = json.loads(await response.text())\n",
    "                response_headers = response.headers\n",
    "\n",
    "                allitems=allitems + parsed\n",
    "                urls = get_links_from_headers(response_headers)\n",
    "                if \"next\" in urls:\n",
    "                    next_url = urls[\"next\"]\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # get the last items of the group\n",
    "    response = requests.get(last_url)\n",
    "    if response.status_code == 200:\n",
    "        parsed = json.loads(response.text)\n",
    "        allitems=allitems + parsed\n",
    "    \n",
    "    return allitems"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test5():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test5 = await get_all_items(session, group_id)\n",
    "        print(test5)\n",
    "asyncio.run(test5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all items of a group library in a json file\n",
    "\n",
    "    Args:\n",
    "        group_id (str): ID of a Zotero group\n",
    "        filename (str): name of the export file including file-extension\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_all_items_to_file(group_id,filename) ->bool: \n",
    "    allitems = get_all_items(group_id)\n",
    "    with open(filename,\"w\") as f:\n",
    "        json.dump(allitems, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#export_all_items_to_file(group_id,\"export_grouplib.json\")\n",
    "with open(\"export_grouplib.json\",\"w\") as f:\n",
    "    json.dump(test5, f)\n",
    "all_items = test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store export in a file and get all item ids\n",
    "\n",
    "The export contains also the note items. These are child items of some other item in this export. They have a parent reference.\n",
    "\n",
    "There are also attachment items. These are child items of some other item in this export. Most of them have a parent reference but some don't have a parent item (anymore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:29:09,573 - Grouplib export json already exists. Delete to fetch again (time consuming).\n",
      "2023-02-25 23:29:10,880 - Exported json.\n"
     ]
    }
   ],
   "source": [
    "json_file = \"export_grouplib.json\"\n",
    "item_ids = []\n",
    "note_ids = []\n",
    "attachment_ids = []\n",
    "async def get_generic_items(session):\n",
    "    if os.path.isfile(json_file):\n",
    "        logging.info(\"Grouplib export json already exists. Delete to fetch again (time consuming).\")\n",
    "        with open(json_file, 'r') as f:\n",
    "            all_items = json.load(f)    \n",
    "    else:\n",
    "        all_items = await get_all_items(session, group_id)\n",
    "    return all_items\n",
    "\n",
    "async def get_export_json():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_generic_items(session)\n",
    "    # all_items = test5\n",
    "    with open(json_file,\"w\") as f:\n",
    "        json.dump(all_items, f)\n",
    "        logging.info(\"Exported json.\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_id = item[\"key\"]\n",
    "        item_type = item[\"data\"][\"itemType\"]\n",
    "        if item_type == 'note':\n",
    "            note_ids.append(item_id)\n",
    "        elif item_type == 'attachment':\n",
    "            attachment_ids.append(item_id)\n",
    "        else:\n",
    "            item_ids.append(item_id)\n",
    "    return all_items\n",
    "all_items = asyncio.run(get_export_json())\n",
    "all_items_map = {data[\"key\"]:data for data in all_items}\n",
    "all_notes_map = {data[\"data\"][\"parentItem\"]:data for data in [all_items_map[id] for id in note_ids]}\n",
    "all_attachments_map = {data[\"data\"][\"parentItem\"] if \"parentItem\" in data[\"data\"] else \"ZZZZZZZZ\":data for data in [all_items_map[id] for id in attachment_ids]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(len(all_items), ' ', len(note_ids), ' ', len(item_ids), '\\n', item_ids[:10],\n",
    "      '\\nBibl items:\\n', dict(list(all_items_map.items())[:10]),\n",
    "      '\\nNote items:\\n', dict(list(all_notes_map.items())[:10]),\n",
    "      '\\nAttachement items:\\n', dict(list(all_attachments_map.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the geo data and replace tags with geo refs\n",
    "\n",
    "geo data is in `../../vicav_biblio/vicav_geodata.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_data = ET.parse(\"../../vicav_biblio/vicav_geodata.xml\")\n",
    "place_by_name = {place.find(\"./tei:placeName\",xmlns).text: \n",
    "                 {\"type\": place.get(\"type\"),\n",
    "                  \"geo\": place.find(\".//tei:geo[@decls='#dd']\",xmlns).text,\n",
    "                  \"el\": place}\n",
    "                for place in geo_data.findall(\".//tei:listPlace/tei:place\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "place_by_name = {}\n",
    "p=1\n",
    "for place in geo_data.findall(\".//tei:listPlace/tei:place\", xmlns):\n",
    "    p=p+1\n",
    "    try:\n",
    "        place_by_name = {**place_by_name, **{place.find(\"./tei:placeName\",xmlns).text: {\"type\": place.get(\"type\"), \"geo\": place.find(\".//tei:geo[@decls='#dd']\",xmlns).text, \"el\": place}}}\n",
    "    except AttributeError:\n",
    "        logging.info(\"Pos \"+str(p)+\" :\"+ET.tostring(place))\n",
    "\n",
    "print(geo_data.find(\".//tei:listPlace\", xmlns)[1].attrib[\"{http://www.w3.org/XML/1998/namespace}id\"], '\\n',\n",
    "    dict(list(place_by_name.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the current mapping for xml:id to Zoteros unique ID\n",
    "\n",
    "Zotero suggests readable @xml:id but those are not unique between runs or  \n",
    "take into account that there may be more than one works by one author in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_zotero_unique_id = re.compile(r'https?://zotero.org/groups/[\\d]+/items/(?P<zuid>[A-Z0-9]+)')\n",
    "current_bibl_data = ET.parse(\"../../vicav_biblio/vicav_biblio_tei_zotero.xml\")\n",
    "xmlid_by_zuid = {get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "xmlid_by_zuid = {}\n",
    "for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns):\n",
    "    try:\n",
    "        xmlid_by_zuid = {**xmlid_by_zuid,\n",
    "                         **{get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")}\n",
    "                        }\n",
    "    except AttributeError:\n",
    "        logging.info(ET.tostring(bibStr))\n",
    "m = get_zotero_unique_id.match(\"http://zotero.org/groups/2165756/items/5XHDCICS\")\n",
    "m.groupdict()\n",
    "xmlid_by_zuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all TEIs from Zotero\n",
    "\n",
    "man nimmt die Liste mit den IDs der entries, baut für jeden entry die URL nach dem Muster  \n",
    "https://api.zotero.org/groups/2165756/items/944KQVKQ?format=tei  \n",
    "man lädt das mit GET requesst  \n",
    "dann aus dem response den body und parsed das mit ET from string, nimmt daraus das  \n",
    "`<biblStruct>` Element;  \n",
    "baut eine gemeinsame `<listBibl>` und fügt das geparste Element ein,  \n",
    "dann dumpt man den ganzen Element-Tree\n",
    "\n",
    "### Retrieves TEI of an item generated by Zotero\n",
    "\n",
    "Resolves place names to geo coordinates using the place by name dict created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "tag_parser = re.compile(r'(?P<geo_type>[^:]+):(?P<geo_name>[^[]+)(\\[(?P<long>[\\d.,]+) +(?P<lat>[\\d.,]+)])?')\n",
    "\n",
    "def create_geo_tag(tags_el, tag):\n",
    "    #starts with reg: geo: diaGroup: -> lookup, get geo location and create elemnt\n",
    "    # uses PEP 634, requires python 3.10+\n",
    "    m = tag_parser.match(tag)\n",
    "    if m is not None:\n",
    "        match m.groupdict():\n",
    "            case {\"geo_type\": \"reg\" | \"geo\" | \"diaGroup\", \"geo_name\": geo_name, \"long\": long, \"lat\": lat}:\n",
    "                tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "                geo_name = geo_name.rstrip()\n",
    "                ET.SubElement(tag_note_el, \"name\", type=m.groupdict()[\"geo_type\"]).text = geo_name\n",
    "                if geo_name in place_by_name:\n",
    "                    ET.SubElement(tag_note_el, \"geo\").text = place_by_name[geo_name][\"geo\"]\n",
    "                else:\n",
    "                    ET.SubElement(tag_note_el, \"note\", type=\"missing_geo_data\")\n",
    "                return tag_note_el\n",
    "    if tag in place_by_name:\n",
    "        tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\", subtype=\"unmarked_geo\")\n",
    "        ET.SubElement(tag_note_el, \"name\", type=place_by_name[tag][\"type\"]).text = tag\n",
    "        ET.SubElement(tag_note_el, \"geo\").text = place_by_name[tag][\"geo\"]\n",
    "        return tag_note_el\n",
    "    ret = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "    ret.text = tag\n",
    "    return ret\n",
    "\n",
    "async def get_item_tei(group_id,item_id,session):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + item_id + \"?format=tei\"\n",
    "    bibl = None\n",
    "    note_for_item_id = \"\"\n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        async with session.get(url=request_url, headers=request_headers) as response:\n",
    "            response_text = await response.text()\n",
    "        list_bibl = ET.fromstring(response_text)\n",
    "        bibl = list_bibl.find(\"tei:biblStruct\",xmlns)\n",
    "        if bibl is None:\n",
    "            logging.info(\"There is no biblStruct in the response for item \" + item_id +\":\\n\"+response_text)\n",
    "            return bibl\n",
    "        zuid = get_zotero_unique_id.match(bibl.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "        current_xmlid = bibl.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        if zuid in xmlid_by_zuid and current_xmlid != xmlid_by_zuid[zuid]:\n",
    "            bibl.set(\"{http://www.w3.org/XML/1998/namespace}id\", xmlid_by_zuid[zuid])\n",
    "            logging.info(\"Changed @xml:id for item \" + item_id + \" from \"+ current_xmlid + \" to \" + xmlid_by_zuid[zuid] + \".\")\n",
    "        if item_id in all_notes_map:\n",
    "            note_for_item_id = all_notes_map[item_id][\"data\"][\"note\"].replace(\"&\", \"&amp;\")\n",
    "            parsed_note = ET.fromstring(\"<note>\"+note_for_item_id+\"</note>\")\n",
    "            bibl.append(parsed_note)\n",
    "        tags = all_items_map[item_id][\"data\"][\"tags\"]\n",
    "        if len(tags) > 0:\n",
    "            tags_el = ET.SubElement(bibl, \"note\", type=\"tags\")\n",
    "            for o in tags:\n",
    "                create_geo_tag(tags_el, o[\"tag\"])\n",
    "                \n",
    "    except asyncio.TimeoutError:\n",
    "        logging.info(\"Timeout fetching \" + item_id)\n",
    "    except xml.etree.ElementTree.ParseError:\n",
    "        logging.info(\"XML parser error in notes for item id \"+item_id+\"\\n\"+note_for_item_id)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + item_id)\n",
    "    logging.info(\"Fetched TEI for \" + item_id)\n",
    "    return bibl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:35:36,279 - Fetched TEI for D25ZTU9X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<biblStruct xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"bookSection\" xml:id=\"Al-Essa_Aziza2022\" corresp=\"http://zotero.org/groups/2165756/items/D25ZTU9X\">\n",
      "  <analytic>\n",
      "    <title level=\"a\">Arabic Interdentals: Variation and Linguistic Change</title>\n",
      "    <author>\n",
      "      <name>Al-Essa, Aziza</name>\n",
      "    </author>\n",
      "  </analytic>\n",
      "  <monogr>\n",
      "    <title level=\"m\">Semitic dialects and dialectology : fieldwork - community - change</title>\n",
      "    <idno type=\"ISBN\">978-3-96822-095-6 / Druck:  9783968220963</idno>\n",
      "    <editor>\n",
      "      <name>Klimiuk, Maciej</name>\n",
      "    </editor>\n",
      "    <imprint>\n",
      "      <pubPlace>Heidelberg</pubPlace>\n",
      "      <biblScope unit=\"page\">45-63</biblScope>\n",
      "      <publisher>Heidelberg University Publishing</publisher>\n",
      "      <date>2022</date>\n",
      "    </imprint>\n",
      "  </monogr>\n",
      "</biblStruct>\n"
     ]
    }
   ],
   "source": [
    "async def get_item_tei_test():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        #test = await get_item_tei(group_id,\"DXNCFAMR\",session)\n",
    "        #test = await get_item_tei(group_id,\"6QNLQCG9\",session)\n",
    "        test = await get_item_tei(group_id,\"D25ZTU9X\",session)\n",
    "    ET.indent(test)\n",
    "    ET.dump(test)\n",
    "asyncio.run(get_item_tei_test())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(\"Notes:\\n\", all_notes_map[\"944KQVKQ\"][\"data\"][\"note\"], \"\\nTags:\\n\", all_items_map[\"944KQVKQ\"][\"data\"][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ET.parse(\"listbibl_template.xml\")\n",
    "list_bibl = template.find(\"tei:text/tei:body/tei:listBibl\",xmlns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load template containing a listBibl-element that will be filled with the retrieved biblStruct elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "ET.dump(list_bibl)\n",
    "list_bibl.append(test)\n",
    "ET.dump(list_bibl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the TEI\n",
    "\n",
    "* For each item-id get the TEI and append it to list-bibl\n",
    "* Save the resulting XML\n",
    "* Save errors for further inspection\n",
    "\n",
    "We need to consider https://www.zotero.org/support/dev/web_api/v3/basics#rate_limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:36:45,044 - Fetching at most 10 TEI/XML.\n",
      "2023-02-25 23:36:45,766 - Fetched TEI for 6KWTRZHW\n",
      "2023-02-25 23:36:45,798 - Changed @xml:id for item 6EPNLRXU from Retsö2009 to Retsö2009b.\n",
      "2023-02-25 23:36:45,800 - Fetched TEI for 6EPNLRXU\n",
      "2023-02-25 23:36:45,802 - Changed @xml:id for item B6L9AIMZ from Retsö2009 to Retsö2009a.\n",
      "2023-02-25 23:36:45,803 - Fetched TEI for B6L9AIMZ\n",
      "2023-02-25 23:36:45,830 - Changed @xml:id for item NPJ679RJ from Arnold2015 to Arnold2015a.\n",
      "2023-02-25 23:36:45,830 - Fetched TEI for NPJ679RJ\n",
      "2023-02-25 23:36:45,832 - Fetched TEI for RCI9I9AM\n",
      "2023-02-25 23:36:45,835 - Fetched TEI for N2NCTC8C\n",
      "2023-02-25 23:36:45,950 - Fetched TEI for E9GJGZZ7\n",
      "2023-02-25 23:36:45,988 - Fetched TEI for JYWMA77R\n",
      "2023-02-25 23:36:45,996 - Fetched TEI for EYRYK2V5\n",
      "2023-02-25 23:36:46,016 - Fetched TEI for QUCSQL79\n",
      "2023-02-25 23:36:46,055 - TEI export done.\n",
      "2023-02-25 23:36:46,056 - Exported errors.json.\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "max_fetch = limit_downloads_to if limit_downloads_to is not None else len(item_ids)\n",
    "logging.info(\"Fetching at most \" + str(max_fetch) + \" TEI/XML.\")\n",
    "async def get_item_tei_from_group(item_id, session):\n",
    "    bibl_struct = await get_item_tei(group_id, item_id, session)\n",
    "    if bibl_struct:\n",
    "        list_bibl.append(bibl_struct)\n",
    "    else:\n",
    "        logging.debug(\"Can not append \" + item_id)\n",
    "        errors.append(item_id)\n",
    "\n",
    "async def async_download():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        await asyncio.gather(*[get_item_tei_from_group(item_id, session) for item_id in item_ids[:max_fetch]])\n",
    "\n",
    "asyncio.run(async_download())\n",
    "\n",
    "list_bibl[:] = sorted(list_bibl, key=lambda child: child.get(\"{http://www.w3.org/XML/1998/namespace}id\"))\n",
    "with open('TEI_export.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8',xml_declaration=True)\n",
    "    logging.info(\"TEI export done.\")\n",
    "\n",
    "# Export IDs of items with errors\n",
    "with open(\"errors.json\",\"w\") as f:\n",
    "    json.dump(errors, f)\n",
    "    logging.info(\"Exported errors.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
