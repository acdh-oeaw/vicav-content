{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script to automate the export and manipulation of the VICAV-library\n",
    "\n",
    "## Import Package eTree to parse XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import asyncio\n",
    "import aiohttp\n",
    "# this module is needed to make asyncio.run work inside the notebook as well as in the generated python script\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define name-space for xml-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmlns = {\"tei\": \"http://www.tei-c.org/ns/1.0\", \"xml\":\"http://www.w3.org/XML/1998/namespace\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access to the VICAV Zotero library\n",
    "\n",
    "* Use API_TOKEN from environment to access Zotero\n",
    "* Set the Zotero group id for VICAV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_headers = {'Authorization': 'Bearer ' + os.environ['API_TOKEN']}\n",
    "group_id = \"2165756\"\n",
    "limit_downloads_to = None\n",
    "conn_limit=16\n",
    "total_timeout=600 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all items in the library\n",
    "\n",
    "Load items from Zotero group library\n",
    "\n",
    "    Args: \n",
    "        group_id (str): ID of a Zotero group\n",
    "        limit (int): number of items to retrieve from library, maximum is 100.\n",
    "        start (int): item number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_items(session, group_id:str,limit:int,start:int,itemType = None):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + \"?limit=\" + str(limit) + \"&start=\" + str(start) + (\"&itemType=\"+itemType if itemType is not None else \"\")\n",
    "    async with session.get(url=request_url, headers=request_headers) as response:\n",
    "        if response.status == 200:\n",
    "            parsed = json.loads(await response.text())\n",
    "            response_headers = response.headers\n",
    "        \n",
    "    return parsed, response_headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test1():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout) # 10 min\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test1, test_reponse_headers = await get_items(session, group_id,10,1000)\n",
    "        test1a, test_reponse_headersa = await get_items(session, group_id,10,300,\"note\")\n",
    "        print(test_reponse_headers, '\\n', test_reponse_headersa, '\\n', len(test1), ' ', len(test1a), '\\n', test1)\n",
    "asyncio.run(test1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get total number of items in group library\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group\n",
    "    \n",
    "    Returns:\n",
    "        int: number of items in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_number_items(group_id) -> int:\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return int(response.headers[\"Total-Results\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test2 = total_number_items(group_id)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get headers of Zotero-Api-Calls\n",
    "\n",
    "    Args:  \n",
    "        group_id (str): ID of a Zotero group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_headers(group_id):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\"\n",
    "    response = requests.get(request_url, headers=request_headers)\n",
    "    \n",
    "    return response.headers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test3 = get_headers(group_id)\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from headers\n",
    "\n",
    "    Args:\n",
    "        headers: http-headers of a response\n",
    "\n",
    "    Returns:\n",
    "        dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_links_from_headers(headers) -> dict:\n",
    "    link_list = headers[\"Link\"].split(\",\")\n",
    "    links = {}\n",
    "    for link_item in link_list:\n",
    "        #print(link_item)\n",
    "        link_type = link_item.split('; rel=\"')[1].replace('\"','').strip()\n",
    "        link_value = link_item.split('; rel=\"')[0].replace(\"<\",\"\").replace(\">\",\"\").strip()\n",
    "        links[link_type] = link_value\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "test_headers = get_headers(group_id)\n",
    "test4 = get_links_from_headers(test_headers)\n",
    "print(test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all items of a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_all_items(session, group_id, itemType = None):\n",
    "    logging.info(\"Getting all items\" + ((\" of type \" + itemType) if itemType is not None else \"\") + \" now.\")\n",
    "    # empty list that will hold all items of the library\n",
    "    allitems=[]\n",
    "    \n",
    "    # settings to be used in the function to get the items (limit is max 100)\n",
    "    limit=100\n",
    "    start=0\n",
    "    \n",
    "    # get the first 200 items to start with\n",
    "    first_round=await get_items(session, group_id,limit,start,itemType)\n",
    "    allitems=allitems+first_round[0]\n",
    "    \n",
    "    # get the next link from the headers\n",
    "    next_url = get_links_from_headers(first_round[1])[\"next\"]\n",
    "    last_url = get_links_from_headers(first_round[1])[\"last\"]\n",
    "    # get items until next url is last url, then all items are fetched\n",
    "    while next_url != last_url:\n",
    "        logging.info(\"Getting items from \" + next_url)\n",
    "        async with session.get(url=next_url, headers=request_headers) as response:\n",
    "            if response.status == 200:\n",
    "                parsed = json.loads(await response.text())\n",
    "                response_headers = response.headers\n",
    "\n",
    "                allitems=allitems + parsed\n",
    "                urls = get_links_from_headers(response_headers)\n",
    "                if \"next\" in urls:\n",
    "                    next_url = urls[\"next\"]\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # get the last items of the group\n",
    "    response = requests.get(last_url)\n",
    "    if response.status_code == 200:\n",
    "        parsed = json.loads(response.text)\n",
    "        allitems=allitems + parsed\n",
    "    \n",
    "    return allitems"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "async def test5():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        test5 = await get_all_items(session, group_id)\n",
    "        print(test5)\n",
    "asyncio.run(test5())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all items of a group library in a json file\n",
    "\n",
    "    Args:\n",
    "        group_id (str): ID of a Zotero group\n",
    "        filename (str): name of the export file including file-extension\n",
    "\n",
    "    Returns:\n",
    "        bool: True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_all_items_to_file(group_id,filename) ->bool: \n",
    "    allitems = get_all_items(group_id)\n",
    "    with open(filename,\"w\") as f:\n",
    "        json.dump(allitems, f)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "#export_all_items_to_file(group_id,\"export_grouplib.json\")\n",
    "with open(\"export_grouplib.json\",\"w\") as f:\n",
    "    json.dump(test5, f)\n",
    "all_items = test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store export in a file and get all item ids\n",
    "\n",
    "The export contains also the note items. These are child items of some other item in this export. They have a parent reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:21:02,490 - Grouplib export json already exists. Delete to fetch again (time consuming).\n",
      "2023-02-24 15:21:03,756 - Exported json.\n"
     ]
    }
   ],
   "source": [
    "json_file = \"export_grouplib.json\"\n",
    "item_ids = []\n",
    "note_ids = []\n",
    "async def get_generic_items(session):\n",
    "    if os.path.isfile(json_file):\n",
    "        logging.info(\"Grouplib export json already exists. Delete to fetch again (time consuming).\")\n",
    "        with open(json_file, 'r') as f:\n",
    "            all_items = json.load(f)    \n",
    "    else:\n",
    "        all_items = await get_all_items(session, group_id)\n",
    "    return all_items\n",
    "\n",
    "async def get_export_json():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        all_items = await get_generic_items(session)\n",
    "    # all_items = test5\n",
    "    with open(json_file,\"w\") as f:\n",
    "        json.dump(all_items, f)\n",
    "        logging.info(\"Exported json.\")\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_id = item[\"key\"]\n",
    "        item_type = item[\"data\"][\"itemType\"]\n",
    "        if item_type == 'note':\n",
    "            note_ids.append(item_id)\n",
    "        else:\n",
    "            item_ids.append(item_id)\n",
    "    return all_items\n",
    "all_items = asyncio.run(get_export_json())\n",
    "all_items_map = {data[\"key\"]:data for data in all_items}\n",
    "all_notes_map = {data[\"data\"][\"parentItem\"]:data for data in [all_items_map[id] for id in note_ids]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(len(all_items), ' ', len(note_ids), ' ', len(item_ids), '\\n', item_ids[:10],\n",
    "      '\\nBibl items:\\n', dict(list(all_items_map.items())[:10]),\n",
    "      '\\nNote items:\\n', dict(list(all_notes_map.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the geo data and replace tags with geo refs\n",
    "\n",
    "geo data is in `../../vicav_biblio/vicav_geodata.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_data = ET.parse(\"../../vicav_biblio/vicav_geodata.xml\")\n",
    "place_by_name = {place.find(\"./tei:placeName\",xmlns).text: \n",
    "                 {\"geo\": place.find(\".//tei:geo[@decls='#dd']\",xmlns).text,\n",
    "                  \"el\": place}\n",
    "                for place in geo_data.findall(\".//tei:listPlace/tei:place\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "place_by_name = {}\n",
    "p=1\n",
    "for place in geo_data.findall(\".//tei:listPlace/tei:place\", xmlns):\n",
    "    p=p+1\n",
    "    try:\n",
    "        place_by_name = {**place_by_name, **{place.find(\"./tei:placeName\",xmlns).text: {\"geo\": place.find(\".//tei:geo[@decls='#dd']\",xmlns).text, \"el\": place}}}\n",
    "    except AttributeError:\n",
    "        logging.info(\"Pos \"+str(p)+\" :\"+ET.tostring(place))\n",
    "\n",
    "print(geo_data.find(\".//tei:listPlace\", xmlns)[1].attrib[\"{http://www.w3.org/XML/1998/namespace}id\"], '\\n',\n",
    "    dict(list(place_by_name.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the current mapping for xml:id to Zoteros unique ID\n",
    "\n",
    "Zotero suggests readable @xml:id but those are not unique between runs or  \n",
    "take into account that there may be more than one works by one author in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_zotero_unique_id = re.compile(r'https?://zotero.org/groups/[\\d]+/items/(?P<zuid>[A-Z0-9]+)')\n",
    "current_bibl_data = ET.parse(\"../../vicav_biblio/vicav_biblio_tei_zotero.xml\")\n",
    "xmlid_by_zuid = {get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "                 for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "xmlid_by_zuid = {}\n",
    "for bibStr in current_bibl_data.findall(\".//tei:biblStruct\", xmlns):\n",
    "    try:\n",
    "        xmlid_by_zuid = {**xmlid_by_zuid,\n",
    "                         **{get_zotero_unique_id.match(bibStr.get(\"corresp\")).groupdict()[\"zuid\"]: bibStr.get(\"{http://www.w3.org/XML/1998/namespace}id\")}\n",
    "                        }\n",
    "    except AttributeError:\n",
    "        logging.info(ET.tostring(bibStr))\n",
    "m = get_zotero_unique_id.match(\"http://zotero.org/groups/2165756/items/5XHDCICS\")\n",
    "m.groupdict()\n",
    "xmlid_by_zuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all TEIs from Zotero\n",
    "\n",
    "man nimmt die Liste mit den IDs der entries, baut für jeden entry die URL nach dem Muster  \n",
    "https://api.zotero.org/groups/2165756/items/944KQVKQ?format=tei  \n",
    "man lädt das mit GET requesst  \n",
    "dann aus dem response den body und parsed das mit ET from string, nimmt daraus das  \n",
    "`<biblStruct>` Element;  \n",
    "baut eine gemeinsame `<listBibl>` und fügt das geparste Element ein,  \n",
    "dann dumpt man den ganzen Element-Tree\n",
    "\n",
    "### Retrieves TEI of an item generated by Zotero\n",
    "\n",
    "Resolves place names to geo coordinates using the place by name dict created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "tag_parser = re.compile(r'(?P<geo_type>[^:]+):(?P<geo_name>[^[]+)(\\[(?P<long>[\\d.,]+) +(?P<lat>[\\d.,]+)])?')\n",
    "\n",
    "def create_geo_tag(tags_el, tag):\n",
    "    #starts with reg: geo: diaGroup: -> lookup, get geo location and create elemnt\n",
    "    # uses PEP 634, requires python 3.10+\n",
    "    m = tag_parser.match(tag)\n",
    "    if m is not None:\n",
    "        match m.groupdict():\n",
    "            case {\"geo_type\": \"reg\" | \"geo\" | \"diaGroup\", \"geo_name\": geo_name, \"long\": long, \"lat\": lat}:\n",
    "                tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\")#, subtype=m.groupdict()[\"geo_type\"])\n",
    "                geo_name = geo_name.rstrip()\n",
    "                ET.SubElement(tag_note_el, \"name\", type=\"geo\").text = geo_name\n",
    "                if geo_name in place_by_name:\n",
    "                    ET.SubElement(tag_note_el, \"geo\").text = place_by_name[geo_name][\"geo\"]\n",
    "                else:\n",
    "                    ET.SubElement(tag_note_el, \"note\", type=\"missing_geo_data\")\n",
    "                return tag_note_el\n",
    "    if tag in place_by_name:\n",
    "        tag_note_el = ET.SubElement(tags_el, \"note\", type=\"tag\", subtype=\"unmarked_geo\")\n",
    "        ET.SubElement(tag_note_el, \"name\", type=\"geo\").text = tag\n",
    "        ET.SubElement(tag_note_el, \"geo\").text = place_by_name[tag][\"geo\"]\n",
    "        return tag_note_el\n",
    "    ret = ET.SubElement(tags_el, \"note\", type=\"tag\")\n",
    "    ret.text = tag\n",
    "    return ret\n",
    "\n",
    "async def get_item_tei(group_id,item_id,session):\n",
    "    request_url = \"https://api.zotero.org/groups/\" + group_id + \"/items/\" + item_id + \"?format=tei\"\n",
    "    bibl = None\n",
    "    note_for_item_id = \"\"\n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        async with session.get(url=request_url, headers=request_headers) as response:\n",
    "            response_text = await response.text()\n",
    "        list_bibl = ET.fromstring(response_text)\n",
    "        bibl = list_bibl.find(\"tei:biblStruct\",xmlns)\n",
    "        if bibl is None:\n",
    "            logging.info(\"There is no biblStruct in the response for item \" + item_id +\":\\n\"+response_text)\n",
    "            return bibl\n",
    "        zuid = get_zotero_unique_id.match(bibl.get(\"corresp\")).groupdict()[\"zuid\"]\n",
    "        current_xmlid = bibl.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        if zuid in xmlid_by_zuid and current_xmlid != xmlid_by_zuid[zuid]:\n",
    "            bibl.set(\"{http://www.w3.org/XML/1998/namespace}id\", xmlid_by_zuid[zuid])\n",
    "            logging.info(\"Changed @xml:id for item \" + item_id + \" from \"+ current_xmlid + \" to \" + xmlid_by_zuid[zuid] + \".\")\n",
    "        if item_id in all_notes_map:\n",
    "            note_for_item_id = all_notes_map[item_id][\"data\"][\"note\"].replace(\"&\", \"&amp;\")\n",
    "            parsed_note = ET.fromstring(\"<note>\"+note_for_item_id+\"</note>\")\n",
    "            bibl.append(parsed_note)\n",
    "        tags_el = ET.SubElement(bibl, \"note\", type=\"tags\")\n",
    "        for o in all_items_map[item_id][\"data\"][\"tags\"]:\n",
    "            create_geo_tag(tags_el, o[\"tag\"])\n",
    "                \n",
    "    except asyncio.TimeoutError:\n",
    "        logging.info(\"Timeout fetching \" + item_id)\n",
    "    except xml.etree.ElementTree.ParseError:\n",
    "        logging.info(\"XML parser error in notes for item id \"+item_id+\"\\n\"+note_for_item_id)\n",
    "    if bibl is None:\n",
    "        logging.debug(\"No biblStruct in item \" + item_id)\n",
    "    logging.info(\"Fetched TEI for \" + item_id)\n",
    "    return bibl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:21:05,102 - Fetched TEI for 6QNLQCG9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<biblStruct xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"book\" xml:id=\"Alhawary2018\" corresp=\"http://zotero.org/groups/2165756/items/6QNLQCG9\">\n",
      "  <monogr>\n",
      "    <title level=\"m\">The Routledge handbook of Arabic second language acquisition</title>\n",
      "    <idno type=\"ISBN\">978-1-138-94055-0</idno>\n",
      "    <idno type=\"callNumber\">PJ6065 .R68 2018</idno>\n",
      "    <editor>\n",
      "      <forename>Mohammad T.</forename>\n",
      "      <surname>Alhawary</surname>\n",
      "    </editor>\n",
      "    <imprint>\n",
      "      <pubPlace>Milton Park, Abingdon, Oxon</pubPlace>\n",
      "      <publisher>New York, NY : Routledge/ Taylor &amp; Francis Group</publisher>\n",
      "      <date>2018</date>\n",
      "    </imprint>\n",
      "  </monogr>\n",
      "  <note>Introduction -- Arabic L2 phonology. the perception and production of Arabic lexical stress by L1 English and L1 Chinese learners of Arabic: a usage-based account / Cheng-Wei Lin and Mohammad T. Alhawary -- Production of modern standard Arabic lexical stress cues by native speakers of American English / Mashael Al-Aloula -- Native English speakers' perception and production of Arabic consonants / Asmaa Shehata -- The perception and production of Arabic consonants: a cross linguistic study / Sara Al Tubuly -- Arabic L2 phonology acquisition: a ultrasound study of emphatics and gutturals / Amanda Eads, Jodi Khater, and Jeff Mielke -- The L2 acquisition of modern standard Arabic final consonant clusters by L1 Chinese speakers / Mona Al Moataz Maamoun -- Arabic L2 vocabulary. Looking at words: an eye-tracking investigation of L2 Arabic vocabulary learning / Ayman A. Mohamed -- Keyword vs context strategies among different levels of Arabic language learners / Olla Najah al-Shalchi -- L2 Arabic of morphosyntax. The acquisition of resumptive pronouns: how do second language learners of Arabic do it? / Dola Algady -- Arabic L2 learners' use of word order and subject-verb agreement for actor role assignment / Jamil Al-Thawahrih -- Arabic L2 reading &amp; corpus-aided language learning. Corpus linguistics and critical reading and thinking: proposals for teaching learning sequences based on journalistic corpora in Modern Standard Arabic / Nadia Makouar -- Arabic L2 writing: discourse analysis &amp; measuring production. Writing in Arabic: discourse analysis and pedagogical reflections / Dris Soulaimani -- Comparing the complexity, accuracy, and fluency of written Arabic in the production of advanced learners and native speakers / Michael Raish -- Arabic L2 speaking &amp; intercultural learning (in study abroad). Research-based interventions for language and intercultural learning / Emma Trentman -- Code-switching in L2 Arabic collaborative dyadic interactions / Khaled Al Masaeed -- Arabic heritage language learners. Proficiency in standard Arabic and its predictors: the case of heritage speakers in college-level elementary Arabic classrooms / Abdulkafi Albirini -- Effect of age of acquisition on concept mediation in heritage Arabic bilinguals / Iyad Ghanim -- The Arabic L2 teacher: teacher training &amp; self-positioning. effect of using a collaborative video-based self- evaluation activity on helping afl student-teachers tie theory to practice / Raghda El Essawi -- \"I am living in a bubble of privilege, [but] I am eternally worried\": two Arabic language users' views on culture and self-positioning as teachers / Brahim Oulbeid</note>\n",
      "  <note type=\"tags\">\n",
      "    <note type=\"tag\">vt:Arabic as a second language</note>\n",
      "    <note type=\"tag\">vt:handbook</note>\n",
      "  </note>\n",
      "</biblStruct>\n"
     ]
    }
   ],
   "source": [
    "async def get_item_tei_test():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        #test = await get_item_tei(group_id,\"944KQVKQ\",session)\n",
    "        #test = await get_item_tei(group_id,\"DXNCFAMR\",session)\n",
    "        test = await get_item_tei(group_id,\"6QNLQCG9\",session)\n",
    "    ET.indent(test)\n",
    "    ET.dump(test)\n",
    "asyncio.run(get_item_tei_test())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "print(\"Notes:\\n\", all_notes_map[\"944KQVKQ\"][\"data\"][\"note\"], \"\\nTags:\\n\", all_items_map[\"944KQVKQ\"][\"data\"][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = ET.parse(\"listbibl_template.xml\")\n",
    "list_bibl = template.find(\"tei:text/tei:body/tei:listBibl\",xmlns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load template containing a listBibl-element that will be filled with the retrieved biblStruct elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "custom",
    "tags": []
   },
   "source": [
    "ET.dump(list_bibl)\n",
    "list_bibl.append(test)\n",
    "ET.dump(list_bibl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the TEI\n",
    "\n",
    "* For each item-id get the TEI and append it to list-bibl\n",
    "* Save the resulting XML\n",
    "* Save errors for further inspection\n",
    "\n",
    "We need to consider https://www.zotero.org/support/dev/web_api/v3/basics#rate_limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:22:21,284 - Fetching at most 100 TEI/XML.\n",
      "2023-02-24 15:22:22,050 - Fetched TEI for RCI9I9AM\n",
      "2023-02-24 15:22:22,066 - Fetched TEI for EYRYK2V5\n",
      "2023-02-24 15:22:22,158 - Changed @xml:id for item 6EPNLRXU from Retsö2009 to Retsö2009b.\n",
      "2023-02-24 15:22:22,161 - Fetched TEI for 6EPNLRXU\n",
      "2023-02-24 15:22:22,186 - Fetched TEI for E9GJGZZ7\n",
      "2023-02-24 15:22:22,226 - Fetched TEI for RUFEDDWU\n",
      "2023-02-24 15:22:22,237 - Changed @xml:id for item NPJ679RJ from Arnold2015 to Arnold2015a.\n",
      "2023-02-24 15:22:22,237 - Fetched TEI for NPJ679RJ\n",
      "2023-02-24 15:22:22,263 - Fetched TEI for N2NCTC8C\n",
      "2023-02-24 15:22:22,270 - Fetched TEI for QUCSQL79\n",
      "2023-02-24 15:22:22,272 - Changed @xml:id for item 4RQ672D6 from Retsö1983 to Retsö1983a.\n",
      "2023-02-24 15:22:22,273 - Fetched TEI for 4RQ672D6\n",
      "2023-02-24 15:22:22,275 - Changed @xml:id for item 5AGSDUQK from Retsö1983 to Retsö1983b.\n",
      "2023-02-24 15:22:22,275 - Fetched TEI for 5AGSDUQK\n",
      "2023-02-24 15:22:22,277 - Fetched TEI for ZPP5LFIZ\n",
      "2023-02-24 15:22:22,287 - Fetched TEI for NIGWMNVB\n",
      "2023-02-24 15:22:22,295 - Fetched TEI for BBB3B6VY\n",
      "2023-02-24 15:22:22,299 - Fetched TEI for JYWMA77R\n",
      "2023-02-24 15:22:22,319 - Changed @xml:id for item B6L9AIMZ from Retsö2009 to Retsö2009a.\n",
      "2023-02-24 15:22:22,320 - Fetched TEI for B6L9AIMZ\n",
      "2023-02-24 15:22:22,321 - Fetched TEI for 6KWTRZHW\n",
      "2023-02-24 15:22:22,519 - Changed @xml:id for item RNJVZ5ZY from Behnstedt1993 to Behnstedt1993b.\n",
      "2023-02-24 15:22:22,522 - Fetched TEI for RNJVZ5ZY\n",
      "2023-02-24 15:22:22,554 - Changed @xml:id for item RLWHIEMA from Lucas2020 to Lucas2020n.\n",
      "2023-02-24 15:22:22,554 - Fetched TEI for RLWHIEMA\n",
      "2023-02-24 15:22:22,619 - Fetched TEI for PYD8MYVU\n",
      "2023-02-24 15:22:22,653 - Fetched TEI for LXDBHINC\n",
      "2023-02-24 15:22:22,663 - Fetched TEI for CUBE7ZWN\n",
      "2023-02-24 15:22:22,698 - Fetched TEI for VFRAUIVS\n",
      "2023-02-24 15:22:22,718 - Fetched TEI for 94YGTTUX\n",
      "2023-02-24 15:22:22,732 - Changed @xml:id for item GLZJDZJ8 from Naïm2006 to Naïm2006b.\n",
      "2023-02-24 15:22:22,732 - Fetched TEI for GLZJDZJ8\n",
      "2023-02-24 15:22:22,735 - Fetched TEI for 7Z7K7GT5\n",
      "2023-02-24 15:22:22,741 - Fetched TEI for M7UJPP23\n",
      "2023-02-24 15:22:22,743 - Fetched TEI for L68WMCM6\n",
      "2023-02-24 15:22:22,744 - Fetched TEI for FHR8ZFB4\n",
      "2023-02-24 15:22:22,745 - Fetched TEI for JQAHK9JL\n",
      "2023-02-24 15:22:22,757 - Changed @xml:id for item VHZ3ZJFP from Durand1995 to Durand1995b.\n",
      "2023-02-24 15:22:22,757 - Fetched TEI for VHZ3ZJFP\n",
      "2023-02-24 15:22:22,764 - Changed @xml:id for item 8PDALG3N from Durand1995 to Durand1995c.\n",
      "2023-02-24 15:22:22,765 - Fetched TEI for 8PDALG3N\n",
      "2023-02-24 15:22:22,791 - Fetched TEI for YHWQXEEK\n",
      "2023-02-24 15:22:22,921 - Fetched TEI for LZZRXQFX\n",
      "2023-02-24 15:22:22,977 - Fetched TEI for JZDS8J9B\n",
      "2023-02-24 15:22:22,999 - Fetched TEI for M6QDWLJX\n",
      "2023-02-24 15:22:23,001 - Changed @xml:id for item Q4YVVGBF from Retsö2014 to Retsö2014b.\n",
      "2023-02-24 15:22:23,002 - Fetched TEI for Q4YVVGBF\n",
      "2023-02-24 15:22:23,013 - Fetched TEI for QQMMM54Z\n",
      "2023-02-24 15:22:23,018 - Fetched TEI for 4TEFG4GR\n",
      "2023-02-24 15:22:23,071 - Changed @xml:id for item H7UD2GEC from Retsö2014 to Retsö2014a.\n",
      "2023-02-24 15:22:23,072 - Fetched TEI for H7UD2GEC\n",
      "2023-02-24 15:22:23,110 - Fetched TEI for RI9A62MM\n",
      "2023-02-24 15:22:23,152 - Fetched TEI for ET9E3AMT\n",
      "2023-02-24 15:22:23,190 - Fetched TEI for ELCV47RV\n",
      "2023-02-24 15:22:23,205 - Fetched TEI for SV9Z4D6Y\n",
      "2023-02-24 15:22:23,221 - Fetched TEI for UGX6U9FI\n",
      "2023-02-24 15:22:23,237 - Fetched TEI for 4U4PXA2U\n",
      "2023-02-24 15:22:23,243 - Fetched TEI for CNWWGLDV\n",
      "2023-02-24 15:22:23,253 - Fetched TEI for 3E63NIP8\n",
      "2023-02-24 15:22:23,255 - Fetched TEI for 6E9C9WVK\n",
      "2023-02-24 15:22:23,286 - Fetched TEI for 7BU9GRUD\n",
      "2023-02-24 15:22:23,292 - Fetched TEI for Y4D4EC7N\n",
      "2023-02-24 15:22:23,317 - Fetched TEI for FERNHSEK\n",
      "2023-02-24 15:22:23,369 - Fetched TEI for H6SUTQTH\n",
      "2023-02-24 15:22:23,436 - Fetched TEI for Y6SXHEX3\n",
      "2023-02-24 15:22:23,490 - Fetched TEI for 7U2D3ZZ5\n",
      "2023-02-24 15:22:23,504 - Fetched TEI for ASDW7JWZ\n",
      "2023-02-24 15:22:23,521 - Fetched TEI for TSVAJM63\n",
      "2023-02-24 15:22:23,540 - Changed @xml:id for item RTU42GAI from Miller2020 to Miller2020b.\n",
      "2023-02-24 15:22:23,541 - Fetched TEI for RTU42GAI\n",
      "2023-02-24 15:22:23,569 - Fetched TEI for AXH49C7Z\n",
      "2023-02-24 15:22:23,610 - Fetched TEI for AIGGEYJV\n",
      "2023-02-24 15:22:23,656 - Changed @xml:id for item W6ZY4Q9I from Leitner2020 to Leitner2020b.\n",
      "2023-02-24 15:22:23,658 - Fetched TEI for W6ZY4Q9I\n",
      "2023-02-24 15:22:23,671 - Fetched TEI for 3UPQD47X\n",
      "2023-02-24 15:22:23,702 - Fetched TEI for 2ZCSZC6S\n",
      "2023-02-24 15:22:23,703 - Fetched TEI for 9KV8ZDXM\n",
      "2023-02-24 15:22:23,720 - Fetched TEI for 5XQZBKWH\n",
      "2023-02-24 15:22:23,763 - Fetched TEI for 8DRBCP9U\n",
      "2023-02-24 15:22:23,765 - Fetched TEI for ZZ7XM6L9\n",
      "2023-02-24 15:22:23,772 - Fetched TEI for VK3JI83R\n",
      "2023-02-24 15:22:23,774 - Changed @xml:id for item YHRMX2NB from Taine-Cheikh2020 to Taine-Cheikh2020b.\n",
      "2023-02-24 15:22:23,774 - Fetched TEI for YHRMX2NB\n",
      "2023-02-24 15:22:23,824 - Changed @xml:id for item JLH7WA7R from Procházka2020 to Procházka2020b.\n",
      "2023-02-24 15:22:23,825 - Fetched TEI for JLH7WA7R\n",
      "2023-02-24 15:22:23,909 - Changed @xml:id for item JR9RHV84 from Ritt-Benmimoun2020 to Ritt-Benmimoun2020c.\n",
      "2023-02-24 15:22:23,911 - Fetched TEI for JR9RHV84\n",
      "2023-02-24 15:22:23,949 - Fetched TEI for DPCK3SDE\n",
      "2023-02-24 15:22:23,969 - Fetched TEI for C27CE3UF\n",
      "2023-02-24 15:22:23,987 - Fetched TEI for GJJ58FYI\n",
      "2023-02-24 15:22:24,010 - Fetched TEI for IX72ZLLZ\n",
      "2023-02-24 15:22:24,018 - Fetched TEI for MXTB9WP8\n",
      "2023-02-24 15:22:24,065 - Fetched TEI for F9J8RRIZ\n",
      "2023-02-24 15:22:24,150 - Fetched TEI for PYDUUBGV\n",
      "2023-02-24 15:22:24,155 - Changed @xml:id for item IM6ZLUC3 from Bettega2022 to Bettega2022a.\n",
      "2023-02-24 15:22:24,155 - Fetched TEI for IM6ZLUC3\n",
      "2023-02-24 15:22:24,157 - Changed @xml:id for item 8Q9L9VE2 from Bettega2022 to Bettega2022b.\n",
      "2023-02-24 15:22:24,158 - Fetched TEI for 8Q9L9VE2\n",
      "2023-02-24 15:22:24,182 - Changed @xml:id for item 32FWAUB3 from Bettega2022 to Bettega2022c.\n",
      "2023-02-24 15:22:24,183 - Fetched TEI for 32FWAUB3\n",
      "2023-02-24 15:22:24,215 - Changed @xml:id for item ZXDFZEVB from Bettega2022 to Bettega2022e.\n",
      "2023-02-24 15:22:24,215 - Fetched TEI for ZXDFZEVB\n",
      "2023-02-24 15:22:24,232 - Changed @xml:id for item FXQSYEGH from Bettega2022 to Bettega2022d.\n",
      "2023-02-24 15:22:24,232 - Fetched TEI for FXQSYEGH\n",
      "2023-02-24 15:22:24,236 - Changed @xml:id for item I43HG54C from Bettega2022 to Bettega2022f.\n",
      "2023-02-24 15:22:24,237 - Fetched TEI for I43HG54C\n",
      "2023-02-24 15:22:24,241 - Changed @xml:id for item ZNAJMUVP from Bettega2022 to Bettega2022g.\n",
      "2023-02-24 15:22:24,241 - Fetched TEI for ZNAJMUVP\n",
      "2023-02-24 15:22:24,256 - Changed @xml:id for item TVS8DCG7 from Bettega2022 to Bettega2022k.\n",
      "2023-02-24 15:22:24,257 - Fetched TEI for TVS8DCG7\n",
      "2023-02-24 15:22:24,279 - Changed @xml:id for item 5L4GDW5I from Bettega2022 to Bettega2022h.\n",
      "2023-02-24 15:22:24,282 - Fetched TEI for 5L4GDW5I\n",
      "2023-02-24 15:22:24,386 - Changed @xml:id for item VXHLTBE4 from Bettega2022 to Bettega2022i.\n",
      "2023-02-24 15:22:24,388 - Fetched TEI for VXHLTBE4\n",
      "2023-02-24 15:22:24,398 - Changed @xml:id for item Z3HC36HT from Bettega2022 to Bettega2022j.\n",
      "2023-02-24 15:22:24,399 - Fetched TEI for Z3HC36HT\n",
      "2023-02-24 15:22:24,441 - Changed @xml:id for item 243IXMTW from Bettega2022 to Bettega2022l.\n",
      "2023-02-24 15:22:24,442 - Fetched TEI for 243IXMTW\n",
      "2023-02-24 15:22:24,459 - Changed @xml:id for item SHBSB66C from Bettega2022 to Bettega2022n.\n",
      "2023-02-24 15:22:24,460 - Fetched TEI for SHBSB66C\n",
      "2023-02-24 15:22:24,472 - Changed @xml:id for item SEVFED87 from Bettega2022 to Bettega2022m.\n",
      "2023-02-24 15:22:24,472 - Fetched TEI for SEVFED87\n",
      "2023-02-24 15:22:24,587 - Changed @xml:id for item RW7V776H from Bettega2022 to Bettega2022p.\n",
      "2023-02-24 15:22:24,591 - Fetched TEI for RW7V776H\n",
      "2023-02-24 15:22:24,617 - Fetched TEI for DB5KVYZ8\n",
      "2023-02-24 15:22:24,622 - Changed @xml:id for item N8LWJJUV from Caubet2000 to Caubet2000d.\n",
      "2023-02-24 15:22:24,623 - Fetched TEI for N8LWJJUV\n",
      "2023-02-24 15:22:24,641 - Changed @xml:id for item 7AXF84RI from Zafrani1988 to Zafrani1988a.\n",
      "2023-02-24 15:22:24,641 - Fetched TEI for 7AXF84RI\n",
      "2023-02-24 15:22:24,656 - Fetched TEI for K9BDS9HU\n",
      "2023-02-24 15:22:24,675 - Fetched TEI for 7GRY9DGF\n",
      "2023-02-24 15:22:24,685 - Changed @xml:id for item 2YNKCJG6 from Taine-Cheikh1989 to Taine-Cheikh1989c.\n",
      "2023-02-24 15:22:24,685 - Fetched TEI for 2YNKCJG6\n",
      "2023-02-24 15:22:24,698 - Fetched TEI for XIZCMCH3\n",
      "2023-02-24 15:22:24,709 - Changed @xml:id for item IEMU68SH from Bettega2022 to Bettega2022o.\n",
      "2023-02-24 15:22:24,710 - Fetched TEI for IEMU68SH\n",
      "2023-02-24 15:22:24,724 - TEI export done.\n",
      "2023-02-24 15:22:24,725 - Exported errors.json.\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "max_fetch = limit_downloads_to if limit_downloads_to is not None else len(item_ids)\n",
    "logging.info(\"Fetching at most \" + str(max_fetch) + \" TEI/XML.\")\n",
    "async def get_item_tei_from_group(item_id, session):\n",
    "    bibl_struct = await get_item_tei(group_id, item_id, session)\n",
    "    if bibl_struct:\n",
    "        list_bibl.append(bibl_struct)\n",
    "    else:\n",
    "        logging.debug(\"Can not append \" + item_id)\n",
    "        errors.append(item_id)\n",
    "\n",
    "async def async_download():\n",
    "    conn = aiohttp.TCPConnector(limit=conn_limit)\n",
    "    timeout = aiohttp.ClientTimeout(total=total_timeout)\n",
    "    async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:\n",
    "        await asyncio.gather(*[get_item_tei_from_group(item_id, session) for item_id in item_ids[:max_fetch]])\n",
    "\n",
    "asyncio.run(async_download())\n",
    "\n",
    "with open('TEI_export.xml', 'wb') as f:\n",
    "    ET.indent(template)\n",
    "    template.write(f, encoding='utf-8')\n",
    "    logging.info(\"TEI export done.\")\n",
    "\n",
    "# Export IDs of items with errors\n",
    "with open(\"errors.json\",\"w\") as f:\n",
    "    json.dump(errors, f)\n",
    "    logging.info(\"Exported errors.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
